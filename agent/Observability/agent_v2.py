import os
import sys
import json
import time
import logging
import requests
from datetime import datetime, timedelta
from typing import Dict, Any, List
import threading
from http.server import HTTPServer, BaseHTTPRequestHandler

from opentelemetry import trace
from opentelemetry.sdk.trace import TracerProvider
from opentelemetry.sdk.trace.export import (
    SimpleSpanProcessor
)
from opentelemetry.sdk.resources import Resource
from opentelemetry.sdk.trace import ReadableSpan

trace.set_tracer_provider(TracerProvider(
    resource=Resource.create({
        "service.name": "weather-ai-agent",
        "service.version": "1.0.0",
        "deployment.environment": "local"
    })
))

logger, log_file = None, None

def format_nanoseconds(ns):
    """–ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ—Ç –Ω–∞–Ω–æ—Å–µ–∫—É–Ω–¥—ã –≤ —á–∏—Ç–∞–µ–º—É—é —Å—Ç—Ä–æ–∫—É datetime"""
    if ns is None:
        return None
    try:
        seconds = ns / 1_000_000_000
        dt = datetime.fromtimestamp(seconds)
        return dt.isoformat()
    except (ValueError, OSError):
        return str(ns)

class JsonSpanExporter:
    """–≠–∫—Å–ø–æ—Ä—Ç–µ—Ä –¥–ª—è –∑–∞–ø–∏—Å–∏ —Ç—Ä–µ–π—Å–æ–≤ –≤ JSON —Ñ–∞–π–ª"""
    def __init__(self):
        if not os.path.exists('traces'):
            os.makedirs('traces')
        
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        self.file_path = f'traces/trace_{timestamp}.json'
        self.spans = []
        
        logger.info(f"üìù JSON —Ç—Ä–µ–π—Å—ã –±—É–¥—É—Ç –∑–∞–ø–∏—Å–∞–Ω—ã –≤: {self.file_path}")
    
    def export(self, batch: List[ReadableSpan]):
        """–≠–∫—Å–ø–æ—Ä—Ç —Å–ø–∞–Ω–æ–≤ –≤ JSON —Ñ–∞–π–ª"""
        try:
            for span in batch:
                span_dict = self._span_to_dict(span)
                self.spans.append(span_dict)
            
            with open(self.file_path, 'w', encoding='utf-8') as f:
                json.dump({
                    "export_time": datetime.now().isoformat(),
                    "total_spans": len(self.spans),
                    "spans": self.spans
                }, f, ensure_ascii=False, indent=2, default=str)
            
            logger.debug(f"‚úÖ –≠–∫—Å–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω–æ {len(batch)} —Å–ø–∞–Ω–æ–≤ –≤ {self.file_path}")
            return True
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ —ç–∫—Å–ø–æ—Ä—Ç–∞ —Ç—Ä–µ–π—Å–æ–≤: {e}")
            return False
    
    def _span_to_dict(self, span: ReadableSpan) -> Dict[str, Any]:
        """–ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è —Å–ø–∞–Ω–∞ –≤ —Å–ª–æ–≤–∞—Ä—å —Å —á–∏—Ç–∞–µ–º—ã–º —Ñ–æ—Ä–º–∞—Ç–æ–º"""
        try:
            span_dict = {
                "name": span.name,
                "context": {
                    "trace_id": format(span.context.trace_id, '032x'),
                    "span_id": format(span.context.span_id, '016x'),
                    "trace_flags": span.context.trace_flags,
                    "is_remote": span.context.is_remote
                } if hasattr(span, 'context') else {},
                "parent_id": format(span.parent.span_id, '016x') if span.parent else None,
                "start_time": format_nanoseconds(span.start_time),
                "end_time": format_nanoseconds(span.end_time),
                "attributes": dict(span.attributes) if span.attributes else {},
                "events": [
                    {
                        "name": event.name,
                        "timestamp": format_nanoseconds(event.timestamp),
                        "attributes": dict(event.attributes) if event.attributes else {}
                    }
                    for event in span.events
                ] if span.events else [],
                "status": {
                    "status_code": span.status.status_code.name,
                    "description": span.status.description
                } if span.status else {},
                "kind": span.kind.name if span.kind else "INTERNAL",
                "resource": dict(span.resource.attributes) if span.resource else {}
            }
            
            if span_dict["attributes"]:
                span_dict["attributes"] = self._decode_dict(span_dict["attributes"])
            
            return span_dict
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏–∏ —Å–ø–∞–Ω–∞: {e}")
            return {"error": str(e), "span_name": span.name}
    
    def _decode_dict(self, data):
        """–†–µ–∫—É—Ä—Å–∏–≤–Ω–æ –¥–µ–∫–æ–¥–∏—Ä—É–µ—Ç Unicode —Å—Ç—Ä–æ–∫–∏ –≤ —Å–ª–æ–≤–∞—Ä–µ"""
        if isinstance(data, dict):
            return {k: self._decode_dict(v) for k, v in data.items()}
        elif isinstance(data, list):
            return [self._decode_dict(item) for item in data]
        elif isinstance(data, str):
            return data
        elif isinstance(data, bytes):
            return data.decode('utf-8', errors='ignore')
        else:
            return data
    
    def shutdown(self):
        """–ó–∞–≤–µ—Ä—à–µ–Ω–∏–µ —Ä–∞–±–æ—Ç—ã —ç–∫—Å–ø–æ—Ä—Ç–µ—Ä–∞"""
        if hasattr(self, 'spans'):
            logger.info(f"‚úÖ –¢—Ä–µ–π—Å—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ {self.file_path}")
            logger.info(f"üìä –í—Å–µ–≥–æ —Å–ø–∞–Ω–æ–≤: {len(self.spans)}")

def setup_logging():
    """–ù–∞—Å—Ç—Ä–æ–π–∫–∞ —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è"""
    global logger, log_file
    
    if not os.path.exists('logs'):
        os.makedirs('logs')

    log_filename = f"logs/weather_agent_{datetime.now().strftime('%Y%m%d_%H%M%S')}.log"

    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s.%(msecs)03d | %(levelname)-8s | %(name)-25s | %(message)s',
        datefmt='%Y-%m-%d %H:%M:%S',
        handlers=[
            logging.FileHandler(log_filename, encoding='utf-8'),
            logging.StreamHandler(sys.stdout)
        ]
    )
    
    logger = logging.getLogger("WeatherAgent")
    logger.info("–ê–≥–µ–Ω—Ç –∑–∞–ø—É—â–µ–Ω")
    logger.info(f"–õ–æ–≥–∏: {log_filename}")
    
    return logger, log_filename

logger, log_file = setup_logging()

json_exporter = JsonSpanExporter()
trace.get_tracer_provider().add_span_processor(
    SimpleSpanProcessor(json_exporter)
)

tracer = trace.get_tracer(__name__)

OPENWEATHER_API_KEY = "0cea8fdbec26b7c76992a739bd2e3d57"
LLM_API_URL = "http://localhost:11434/api/generate"

PROMPT_VERSION = "1.0"
system_prompt = f"""–í–µ—Ä—Å–∏—è –ø—Ä–æ–º–ø—Ç–∞: {PROMPT_VERSION}
–¢—ã - –ø–æ–ª–µ–∑–Ω—ã–π –ø–æ–≥–æ–¥–Ω—ã–π –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç. –¢–≤–æ—è –∑–∞–¥–∞—á–∞ - –¥–∞–≤–∞—Ç—å —á–µ—Ç–∫–∏–µ –∏ –≤–µ–∂–ª–∏–≤—ã–µ –æ—Ç–≤–µ—Ç—ã –æ –ø–æ–≥–æ–¥–µ –Ω–∞ –æ—Å–Ω–æ–≤–µ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö.
–ù–µ –æ–±—Ä–∞—â–∞–π—Å—è –∫ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—é, —Å—Ä–∞–∑—É –æ—Ç–≤–µ—Ç. –ù–µ –Ω–∞–¥–æ –ø–∏—Å–∞—Ç—å –æ—Ç–∫—É–¥–∞ –ø–æ–ª—É—á–∏–ª –¥–∞–Ω–Ω—ã–µ. –í –æ—Ç–≤–µ—Ç–µ —É–ø–æ–º–∏–Ω–∞–π –≥–æ—Ä–æ–¥.
–ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π –¥–∞–Ω–Ω—ã–µ –æ –ø–æ–≥–æ–¥–µ –∏ —Å–≥–µ–Ω–µ—Ä–∏—Ä—É–π –∫—Ä–∞—Ç–∫–∏–π –∏ –¥—Ä—É–∂–µ–ª—é–±–Ω—ã–π –æ—Ç–≤–µ—Ç –Ω–∞ —Ä—É—Å—Å–∫–æ–º —è–∑—ã–∫–µ, –∫–æ—Ç–æ—Ä—ã–π –≤–∫–ª—é—á–∞–µ—Ç:
- –û–±—â–µ–µ –æ–ø–∏—Å–∞–Ω–∏–µ –ø–æ–≥–æ–¥—ã
- –¢–µ–∫—É—â—É—é —Ç–µ–º–ø–µ—Ä–∞—Ç—É—Ä—É –≤ –≥—Ä–∞–¥—É—Å–∞—Ö –¶–µ–ª—å—Å–∏—è, –æ–∫—Ä—É–≥–ª—è–π –¥–æ —Ü–µ–ª—ã—Ö
- –û—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω—É—é –≤–ª–∞–∂–Ω–æ—Å—Ç—å –≤–æ–∑–¥—É—Ö–∞
- –°–∫–æ—Ä–æ—Å—Ç—å –≤–µ—Ç—Ä–∞
- –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –ø–æ –æ–¥–µ–∂–¥–µ –∏ –∞–∫—Å–µ—Å—Å—É–∞—Ä–∞—Ö (–ø–æ–¥—Ä–æ–±–Ω–æ)
- –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –∫—É–¥–∞ –≤ —Ç–∞–∫—É—é –ø–æ–≥–æ–¥—É –ª—É—á—à–µ –≤—Å–µ–≥–æ —Å—Ö–æ–¥–∏—Ç—å (–º–Ω–æ–≥–æ –≤–∞—Ä–∏–∞–Ω—Ç–æ–≤)

–ë—É–¥—å —Ç–æ—á–µ–Ω, –æ—Ç–≤–µ—Ç—ã —Ä–∞–∑–≤–µ—Ä–Ω—É—Ç—ã–µ. –ù–µ –ø—Ä–∏–¥—É–º—ã–≤–∞–π –¥–∞–Ω–Ω—ã–µ, –∫–æ—Ç–æ—Ä—ã—Ö –Ω–µ—Ç –≤ –æ—Ç–≤–µ—Ç–µ –æ—Ç API. –°–æ–≤–µ—Ç—É–π —Ç–æ–ª—å–∫–æ —Ç–æ —á—Ç–æ –ø–æ –ø–æ–≥–æ–¥–µ –ø–æ–¥—Ö–æ–¥–∏—Ç.
"""

class MetricsCollector:
    """–°–±–æ—Ä –º–µ—Ç—Ä–∏–∫"""
    def __init__(self):
        self.metrics = {
            'requests_total': 0,
            'requests_success': 0,
            'requests_failed': 0,
            'weather_api_calls': 0,
            'llm_api_calls': 0,
            'total_tokens': 0,
            'errors': {},
            'latencies': {
                'weather_api': [],
                'llm_api': [],
                'total_request': []
            },
            'start_time': datetime.now()
        }
    
    def record_request(self, success=True):
        self.metrics['requests_total'] += 1
        if success:
            self.metrics['requests_success'] += 1
        else:
            self.metrics['requests_failed'] += 1
    
    def record_api_call(self, api_name: str):
        if api_name == 'weather':
            self.metrics['weather_api_calls'] += 1
        elif api_name == 'llm':
            self.metrics['llm_api_calls'] += 1
    
    def record_latency(self, operation: str, latency_ms: float):
        if operation in self.metrics['latencies']:
            self.metrics['latencies'][operation].append(latency_ms)
    
    def record_tokens(self, tokens: int):
        self.metrics['total_tokens'] += tokens
    
    def record_error(self, error_type: str):
        self.metrics['errors'][error_type] = self.metrics['errors'].get(error_type, 0) + 1
    
    def get_summary(self) -> Dict[str, Any]:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ —Å–≤–æ–¥–∫–∏ –º–µ—Ç—Ä–∏–∫"""
        uptime = datetime.now() - self.metrics['start_time']
        
        avg_latencies = {}
        for op, latencies in self.metrics['latencies'].items():
            if latencies:
                avg_latencies[op] = sum(latencies) / len(latencies)
            else:
                avg_latencies[op] = 0
        
        success_rate = 0
        if self.metrics['requests_total'] > 0:
            success_rate = (self.metrics['requests_success'] / self.metrics['requests_total']) * 100
        
        return {
            'uptime': str(uptime),
            'requests_total': self.metrics['requests_total'],
            'requests_success': self.metrics['requests_success'],
            'requests_failed': self.metrics['requests_failed'],
            'success_rate': round(success_rate, 2),
            'weather_api_calls': self.metrics['weather_api_calls'],
            'llm_api_calls': self.metrics['llm_api_calls'],
            'total_tokens': self.metrics['total_tokens'],
            'avg_latencies': avg_latencies,
            'errors': self.metrics['errors'],
            'prompt_version': PROMPT_VERSION
        }


metrics = MetricsCollector()


class MetricsHandler(BaseHTTPRequestHandler):
    """–û–±—Ä–∞–±–æ—Ç—á–∏–∫ –¥–ª—è –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω–∏—è –º–µ—Ç—Ä–∏–∫ –≤ —Ñ–æ—Ä–º–∞—Ç–µ Prometheus"""
    
    def do_GET(self):
        if self.path == '/metrics':
            self.send_response(200)
            self.send_header('Content-Type', 'text/plain')
            self.end_headers()
            summary = metrics.get_summary()
            
            metrics_text = f"""
# HELP weather_agent_requests_total Total number of requests
# TYPE weather_agent_requests_total counter
weather_agent_requests_total {summary['requests_total']}

# HELP weather_agent_requests_success Successful requests  
# TYPE weather_agent_requests_success counter
weather_agent_requests_success {summary['requests_success']}

# HELP weather_agent_weather_api_calls Weather API calls
# TYPE weather_agent_weather_api_calls counter
weather_agent_weather_api_calls {summary['weather_api_calls']}

# HELP weather_agent_llm_api_calls LLM API calls
# TYPE weather_agent_llm_api_calls counter
weather_agent_llm_api_calls {summary['llm_api_calls']}

# HELP weather_agent_total_tokens Total tokens used
# TYPE weather_agent_total_tokens counter
weather_agent_total_tokens {summary['total_tokens']}

# HELP weather_agent_success_rate Success rate percentage
# TYPE weather_agent_success_rate gauge
weather_agent_success_rate {summary['success_rate']}
"""
            self.wfile.write(metrics_text.encode())
        else:
            self.send_response(404)
            self.end_headers()


def start_metrics_server(port=8000):
    """–ó–∞–ø—É—Å–∫ HTTP —Å–µ—Ä–≤–µ—Ä–∞ –¥–ª—è –º–µ—Ç—Ä–∏–∫"""
    server = HTTPServer(('localhost', port), MetricsHandler)
    logger.info(f"üìä –°–µ—Ä–≤–µ—Ä –º–µ—Ç—Ä–∏–∫ –∑–∞–ø—É—â–µ–Ω –Ω–∞ http://localhost:{port}/metrics")
    server.serve_forever()


def get_weather_data(city_name: str, hours_ahead: int = 0) -> Dict[str, Any]:
    """
    –ü–æ–ª—É—á–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö –æ –ø–æ–≥–æ–¥–µ —Å —Ç—Ä–µ–π—Å–∏–Ω–≥–æ–º
    """
    with tracer.start_as_current_span("get_weather_data") as span:
        span.set_attributes({
            "city": city_name,
            "hours_ahead": hours_ahead,
            "api": "openweathermap",
            "prompt_version": PROMPT_VERSION
        })
        
        logger.info(f"–ó–∞–ø—Ä–æ—Å –ø–æ–≥–æ–¥—ã: {city_name}, –ø—Ä–æ–≥–Ω–æ–∑ –Ω–∞ {hours_ahead}—á")
        
        try:
            start_time = time.time()
            
            if hours_ahead == 0:
                url = "http://api.openweathermap.org/data/2.5/weather"
            else:
                url = "http://api.openweathermap.org/data/2.5/forecast"

            params = {
                'q': city_name,
                'appid': OPENWEATHER_API_KEY,
                'units': 'metric',
                'lang': 'ru'
            }

            response = requests.get(url, params=params, timeout=10)
            response.raise_for_status()
            
            latency_ms = (time.time() - start_time) * 1000
            metrics.record_latency('weather_api', latency_ms)
            metrics.record_api_call('weather')
            
            data = response.json()
            
            if hours_ahead > 0 and 'list' in data:
                target_time = datetime.now() + timedelta(hours=hours_ahead)
                closest_forecast = None
                min_time_diff = float('inf')

                for forecast in data['list']:
                    forecast_time = datetime.fromtimestamp(forecast['dt'])
                    time_diff = abs((forecast_time - target_time).total_seconds())

                    if time_diff < min_time_diff:
                        min_time_diff = time_diff
                        closest_forecast = forecast

                if closest_forecast:
                    weather_info = {
                        'name': data['city']['name'],
                        'weather': closest_forecast['weather'],
                        'main': closest_forecast['main'],
                        'wind': closest_forecast.get('wind', {}),
                        'visibility': closest_forecast.get('visibility', 10000),
                        'dt': closest_forecast['dt'],
                        'forecast_time': closest_forecast['dt_txt'],
                        'is_forecast': True
                    }
                    
                    span.add_event("forecast_retrieved", {
                        "temperature": closest_forecast['main']['temp'],
                        "condition": closest_forecast['weather'][0]['description']
                    })
                    
                    logger.info(f"–ü—Ä–æ–≥–Ω–æ–∑ –ø–æ–ª—É—á–µ–Ω: {weather_info['name']}, —Ç–µ–º–ø–µ—Ä–∞—Ç—É—Ä–∞={weather_info['main']['temp']}¬∞C")
                    return weather_info
                else:
                    metrics.record_error("forecast_not_found")
                    logger.warning(f"–ü—Ä–æ–≥–Ω–æ–∑ –Ω–µ –Ω–∞–π–¥–µ–Ω –¥–ª—è {city_name} —á–µ—Ä–µ–∑ {hours_ahead}—á")
                    return {"error": "–ù–µ —É–¥–∞–ª–æ—Å—å –Ω–∞–π—Ç–∏ –ø—Ä–æ–≥–Ω–æ–∑ –¥–ª—è —É–∫–∞–∑–∞–Ω–Ω–æ–≥–æ –≤—Ä–µ–º–µ–Ω–∏"}

            if 'main' in data:
                span.add_event("weather_retrieved", {
                    "temperature": data['main']['temp'],
                    "humidity": data['main']['humidity']
                })
                
                logger.info(f"–ì–æ—Ä–æ–¥: {data.get('name', 'unknown')}, —Ç–µ–º–ø–µ—Ä–∞—Ç—É—Ä–∞={data['main']['temp']}¬∞C")
                return data
            
            return {"error": "–ù–µ–≤–µ—Ä–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç –¥–∞–Ω–Ω—ã—Ö –æ—Ç API"}

        except requests.exceptions.Timeout:
            error_msg = f"–¢–∞–π–º–∞—É—Ç –ø—Ä–∏ –∑–∞–ø—Ä–æ—Å–µ –ø–æ–≥–æ–¥—ã: {city_name}"
            logger.error(error_msg)
            span.record_exception(Exception(error_msg))
            metrics.record_error("weather_api_timeout")
            return {"error": error_msg}
        except requests.exceptions.RequestException as e:
            error_msg = f"–û—à–∏–±–∫–∞ API –ø–æ–≥–æ–¥—ã: {e}"
            logger.error(error_msg)
            span.record_exception(e)
            metrics.record_error("weather_api_error")
            return {"error": error_msg}
        except Exception as e:
            error_msg = f"–ù–µ–æ–∂–∏–¥–∞–Ω–Ω–∞—è –æ—à–∏–±–∫–∞: {e}"
            logger.error(error_msg, exc_info=True)
            span.record_exception(e)
            metrics.record_error("unexpected_error")
            return {"error": error_msg}


def ask_llm(weather_data: Dict[str, Any]) -> str:
    """
    –ó–∞–ø—Ä–æ—Å –∫ LLM —Å —Ç—Ä–µ–π—Å–∏–Ω–≥–æ–º –∏ —Å–±–æ—Ä–æ–º LLM-—Å–ø–µ—Ü–∏—Ñ–∏—á–Ω—ã—Ö –º–µ—Ç—Ä–∏–∫
    """
    with tracer.start_as_current_span("ask_llm") as span:
        span.set_attributes({
            "llm.model": "llama3.1:8b",
            "llm.provider": "ollama",
            "prompt.version": PROMPT_VERSION,
            "weather.city": weather_data.get('name', 'unknown')
        })
        
        logger.info(f"–ó–∞–ø—Ä–æ—Å –∫ LLM: –≥–æ—Ä–æ–¥={weather_data.get('name', 'unknown')}")
        
        try:
            prompt_text = f"{system_prompt}\n\n–î–∞–Ω–Ω—ã–µ –æ –ø–æ–≥–æ–¥–µ: {json.dumps(weather_data, ensure_ascii=False)}"
            
            payload = {
                "model": "llama3.1:8b",
                "prompt": prompt_text,
                "stream": False,
                "options": {
                    "temperature": 0.7,
                    "num_predict": 512,
                    "top_p": 0.9
                }
            }
            
            span.add_event("prompt_sent", {
                "prompt_length": len(prompt_text),
                "prompt_version": PROMPT_VERSION
            })
            
            start_time = time.time()
            
            response = requests.post(LLM_API_URL, json=payload)
            
            response.raise_for_status()
            
            latency_ms = (time.time() - start_time) * 1000
            metrics.record_latency('llm_api', latency_ms)
            metrics.record_api_call('llm')
            
            result = response.json()
            response_text = result.get("response", "")
            
            prompt_tokens = result.get("prompt_eval_count")
            completion_tokens = result.get("eval_count")
            
            if prompt_tokens and completion_tokens:
                total_tokens = prompt_tokens + completion_tokens
                metrics.record_tokens(total_tokens)
                
                span.set_attributes({
                    "llm.tokens.prompt": prompt_tokens,
                    "llm.tokens.completion": completion_tokens,
                    "llm.tokens.total": total_tokens
                })
                
                span.add_event("tokens_used", {
                    "prompt_tokens": prompt_tokens,
                    "completion_tokens": completion_tokens,
                    "total_tokens": total_tokens
                })
                
                logger.info(f"–¢–æ–∫–µ–Ω—ã –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω—ã: prompt={prompt_tokens}, completion={completion_tokens}")
            
            span.add_event("response_received", {
                "response_length": len(response_text),
                "latency_ms": latency_ms
            })
            
            logger.info(f"LLM –æ—Ç–≤–µ—Ç: {len(response_text)} —Å–∏–º–≤–æ–ª–æ–≤, –≤—Ä–µ–º—è={latency_ms:.0f}–º—Å")
            
            return response_text

        except requests.exceptions.ConnectionError:
            error_msg = "–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–¥–∫–ª—é—á–∏—Ç—å—Å—è –∫ Ollama. –£–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ Ollama –∑–∞–ø—É—â–µ–Ω."
            logger.error(error_msg)
            span.record_exception(Exception(error_msg))
            metrics.record_error("llm_connection_error")
            return f"‚ö†Ô∏è {error_msg}"
        except requests.exceptions.RequestException as e:
            error_msg = f"–û—à–∏–±–∫–∞ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è –∫ LLM: {e}"
            logger.error(error_msg)
            span.record_exception(e)
            metrics.record_error("llm_api_error")
            return f"‚ö†Ô∏è {error_msg}"
        except Exception as e:
            error_msg = f"–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ LLM-–æ—Ç–≤–µ—Ç–∞: {e}"
            logger.error(error_msg, exc_info=True)
            span.record_exception(e)
            metrics.record_error("llm_processing_error")
            return f"‚ö†Ô∏è {error_msg}"


def process_weather_request(city: str, hours_ahead: int = 0) -> Dict[str, Any]:
    """
    –û–±—Ä–∞–±–æ—Ç–∫–∞ –ø–æ–ª–Ω–æ–≥–æ –∑–∞–ø—Ä–æ—Å–∞ —Å —Ç—Ä–µ–π—Å–∏–Ω–≥–æ–º –≤—Å–µ–π —Ü–µ–ø–æ—á–∫–∏
    """
    with tracer.start_as_current_span("process_weather_request") as span:
        span.set_attributes({
            "request.city": city,
            "request.hours_ahead": hours_ahead,
            "request.prompt_version": PROMPT_VERSION
        })
        
        logger.info(f"–ù–∞—á–∞–ª–æ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∑–∞–ø—Ä–æ—Å–∞: {city}, –ø—Ä–æ–≥–Ω–æ–∑ –Ω–∞ {hours_ahead}—á")
        
        try:
            start_time = time.time()
            
            weather_data = get_weather_data(city, hours_ahead)
            
            if "error" in weather_data:
                span.set_attribute("request.success", False)
                span.add_event("weather_api_failed", {"error": weather_data["error"]})
                metrics.record_request(success=False)
                metrics.record_error("weather_data_error")
                return {
                    "success": False,
                    "error": weather_data["error"],
                    "city": city
                }
            
            llm_response = ask_llm(weather_data)
            
            total_latency = (time.time() - start_time) * 1000
            metrics.record_latency('total_request', total_latency)
            
            if "‚ö†Ô∏è" in llm_response:
                span.set_attribute("request.success", False)
                metrics.record_request(success=False)
                result = {
                    "success": False,
                    "city": city,
                    "response": llm_response,
                    "latency_ms": total_latency
                }
            else:
                span.set_attribute("request.success", True)
                span.add_event("request_completed", {
                    "total_latency_ms": total_latency,
                    "response_length": len(llm_response)
                })
                metrics.record_request(success=True)
                result = {
                    "success": True,
                    "city": city,
                    "response": llm_response,
                    "latency_ms": total_latency,
                    "prompt_version": PROMPT_VERSION
                }
            
            span.set_attribute("request.latency_ms", total_latency)
            logger.info(f"–ó–∞–ø—Ä–æ—Å –∑–∞–≤–µ—Ä—à–µ–Ω: —É—Å–ø–µ—Ö={result['success']}, –≤—Ä–µ–º—è={total_latency:.0f}–º—Å")
            
            return result
            
        except Exception as e:
            error_msg = f"–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∑–∞–ø—Ä–æ—Å–∞: {e}"
            logger.error(error_msg, exc_info=True)
            span.record_exception(e)
            span.set_attribute("request.success", False)
            metrics.record_request(success=False)
            metrics.record_error("request_processing_error")
            return {
                "success": False,
                "error": error_msg,
                "city": city
            }


def display_dashboard():
    """–û—Ç–æ–±—Ä–∞–∂–µ–Ω–∏–µ –¥–∞—à–±–æ—Ä–¥–∞ –≤ –∫–æ–Ω—Å–æ–ª–∏"""
    os.system('cls' if os.name == 'nt' else 'clear')
    
    metrics_summary = metrics.get_summary()
    
    print("=" * 80)
    print("üå§Ô∏è  –ü–û–ì–û–î–ù–´–ô –ò–ò-–ê–ì–ï–ù–¢ –° –ü–û–õ–ù–û–ô –°–ò–°–¢–ï–ú–û–ô OBSERVABILITY")
    print("=" * 80)
    print(f"üìÖ –í—Ä–µ–º—è: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print(f"üìä –ú–µ—Ç—Ä–∏–∫–∏: http://localhost:8000/metrics")
    print(f"üìÅ –õ–æ–≥–∏: {log_file}")
    print(f"üìù –¢—Ä–µ–π—Å—ã: {json_exporter.file_path}")
    print(f"üîß –í–µ—Ä—Å–∏—è –ø—Ä–æ–º–ø—Ç–∞: {PROMPT_VERSION}")
    print(f"üìà –ó–∞–ø—Ä–æ—Å–æ–≤: {metrics_summary['requests_total']}")
    print(f"‚úÖ –£—Å–ø–µ—à–Ω–æ: {metrics_summary['requests_success']}")
    print(f"‚ùå –û—à–∏–±–æ–∫: {metrics_summary['requests_failed']}")
    print(f"üìä –£—Å–ø–µ—à–Ω–æ—Å—Ç—å: {metrics_summary['success_rate']}%")
    print("-" * 80)


def main():
    metrics_thread = threading.Thread(target=start_metrics_server, daemon=True)
    metrics_thread.start()
    
    print("   –í—Å–µ –∑–∞–ø—Ä–æ—Å—ã –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –æ—Ç—Å–ª–µ–∂–∏–≤–∞—é—Ç—Å—è.")
    print("   –ú–µ—Ç—Ä–∏–∫–∏ –¥–æ—Å—Ç—É–ø–Ω—ã –Ω–∞ http://localhost:8000/metrics")
    print("\n" + "=" * 80)
    
    time.sleep(1)  # –î–∞—é –≤—Ä–µ–º—è —Å–µ—Ä–≤–µ—Ä—É –º–µ—Ç—Ä–∏–∫ –∑–∞–ø—É—Å—Ç–∏—Ç—å—Å—è
    
    while True:
        display_dashboard()
        
        print(f"\nüìã –ù–æ–≤—ã–π –∑–∞–ø—Ä–æ—Å")
        print("-" * 40)
        
        city = input("üèôÔ∏è  –í–≤–µ–¥–∏—Ç–µ –≥–æ—Ä–æ–¥ (–∏–ª–∏ '–≤—ã—Ö–æ–¥' –¥–ª—è –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è): ").strip()

        if city.lower() in ['–≤—ã—Ö–æ–¥', 'exit', 'quit', 'q']:
            print("\n" + "=" * 80)
            print("üìä –§–ò–ù–ê–õ–¨–ù–ê–Ø –°–¢–ê–¢–ò–°–¢–ò–ö–ê:")
            summary = metrics.get_summary()
            for key, value in summary.items():
                if isinstance(value, dict):
                    print(f"   {key}:")
                    for k, v in value.items():
                        if isinstance(v, dict):
                            print(f"     - {k}:")
                            for k2, v2 in v.items():
                                print(f"       * {k2}: {v2}")
                        else:
                            print(f"     - {k}: {v}")
                else:
                    print(f"   {key}: {value}")
            print(f"\nüìÅ –õ–æ–≥–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤: {log_file}")
            print(f"üìù –¢—Ä–µ–π—Å—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤: {json_exporter.file_path}")
            print("üëã –î–æ —Å–≤–∏–¥–∞–Ω–∏—è!")
            print("=" * 80)
            break

        if not city:
            print("‚ö†Ô∏è  –ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –≤–≤–µ–¥–∏—Ç–µ –Ω–∞–∑–≤–∞–Ω–∏–µ –≥–æ—Ä–æ–¥–∞.")
            continue

        time_input = input("‚è∞ –ß–µ—Ä–µ–∑ —Å–∫–æ–ª—å–∫–æ —á–∞—Å–æ–≤ –ø—Ä–æ–≥–Ω–æ–∑? (0 –¥–ª—è —Ç–µ–∫—É—â–µ–π –ø–æ–≥–æ–¥—ã): ").strip()

        try:
            hours_ahead = int(time_input) if time_input else 0
            if hours_ahead < 0:
                print("‚ö†Ô∏è  –í—Ä–µ–º—è –Ω–µ –º–æ–∂–µ—Ç –±—ã—Ç—å –æ—Ç—Ä–∏—Ü–∞—Ç–µ–ª—å–Ω—ã–º. –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è —Ç–µ–∫—É—â–∞—è –ø–æ–≥–æ–¥–∞.")
                hours_ahead = 0
        except ValueError:
            print("‚ö†Ô∏è  –ù–µ–≤–µ—Ä–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç –≤—Ä–µ–º–µ–Ω–∏. –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è —Ç–µ–∫—É—â–∞—è –ø–æ–≥–æ–¥–∞.")
            hours_ahead = 0

        if hours_ahead > 120:
            print("‚ö†Ô∏è  –ü—Ä–æ–≥–Ω–æ–∑ –¥–æ—Å—Ç—É–ø–µ–Ω —Ç–æ–ª—å–∫–æ –Ω–∞ 5 –¥–Ω–µ–π (120 —á–∞—Å–æ–≤). –£—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–æ 120 —á–∞—Å–æ–≤.")
            hours_ahead = 120

        print(f"\nüîç –û–±—Ä–∞–±–∞—Ç—ã–≤–∞—é –∑–∞–ø—Ä–æ—Å –¥–ª—è {city}...")
        
        result = process_weather_request(city, hours_ahead)
        
        print("\n" + "=" * 80)
        print("üå§Ô∏è  –ü–û–ì–û–î–ù–´–ô –ü–†–û–ì–ù–û–ó")
        print("=" * 80)
        
        if result["success"]:
            response = result["response"]
            print(response)
            
            print("\n" + "=" * 80)
            print(f"üìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –∑–∞–ø—Ä–æ—Å–∞:")
            print(f"   ‚Ä¢ –ì–æ—Ä–æ–¥: {result['city']}")
            print(f"   ‚Ä¢ –í—Ä–µ–º—è –æ–±—Ä–∞–±–æ—Ç–∫–∏: {result.get('latency_ms', 0):.0f}–º—Å")
            print(f"   ‚Ä¢ –î–ª–∏–Ω–∞ –æ—Ç–≤–µ—Ç–∞: {len(response)} —Å–∏–º–≤–æ–ª–æ–≤")
            print(f"   ‚Ä¢ –í–µ—Ä—Å–∏—è –ø—Ä–æ–º–ø—Ç–∞: {result.get('prompt_version', 'N/A')}")
        else:
            print(f"‚ùå –û—à–∏–±–∫–∞: {result.get('error', result.get('response', '–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–∞—è –æ—à–∏–±–∫–∞'))}")
            print("=" * 80)
        
        print("üìà –í—Å–µ –º–µ—Ç—Ä–∏–∫–∏ –¥–æ—Å—Ç—É–ø–Ω—ã –Ω–∞ http://localhost:8000/metrics")
        
        input("\n‚Üµ –ù–∞–∂–º–∏—Ç–µ Enter –¥–ª—è —Å–ª–µ–¥—É—é—â–µ–≥–æ –∑–∞–ø—Ä–æ—Å–∞...")


if __name__ == "__main__":
    try:
        try:
            test_response = requests.get("http://localhost:11434/api/tags", timeout=2)
            if test_response.status_code == 200:
                logger.info("‚úÖ Ollama –¥–æ—Å—Ç—É–ø–µ–Ω")
            else:
                logger.warning("‚ö†Ô∏è  Ollama –Ω–µ –æ—Ç–≤–µ—á–∞–µ—Ç –¥–æ–ª–∂–Ω—ã–º –æ–±—Ä–∞–∑–æ–º")
        except:
            logger.warning("‚ö†Ô∏è  Ollama –Ω–µ –∑–∞–ø—É—â–µ–Ω. LLM-—Ñ—É–Ω–∫—Ü–∏–æ–Ω–∞–ª—å–Ω–æ—Å—Ç—å –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–∞.")
            print("‚ö†Ô∏è  –í–ù–ò–ú–ê–ù–ò–ï: Ollama –Ω–µ –∑–∞–ø—É—â–µ–Ω!")
            print("   –ó–∞–ø—É—Å—Ç–∏—Ç–µ Ollama –≤ –æ—Ç–¥–µ–ª—å–Ω–æ–º —Ç–µ—Ä–º–∏–Ω–∞–ª–µ –ø–µ—Ä–µ–¥ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º LLM")
            print("   –ö–æ–º–∞–Ω–¥–∞: ollama serve")
        
        main()
        
    except KeyboardInterrupt:
        print("\n\nüëã –ü—Ä–æ–≥—Ä–∞–º–º–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞ –ø–æ –∑–∞–ø—Ä–æ—Å—É –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è")
        json_exporter.shutdown()
        logger.info("–ü—Ä–æ–≥—Ä–∞–º–º–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞ –ø–æ –∑–∞–ø—Ä–æ—Å—É –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è")
    except Exception as e:
        logger.error(f"–ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞: {e}", exc_info=True)
        print(f"\n‚ùå –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞: {e}")
        print("–ü—Ä–æ–≤–µ—Ä—å—Ç–µ —Ñ–∞–π–ª –ª–æ–≥–æ–≤ –¥–ª—è –¥–µ—Ç–∞–ª–µ–π.")